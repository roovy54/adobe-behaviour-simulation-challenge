{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Script to build analogy db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import swifter\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from urllib.request import urlopen\n",
    "from Encoder import MultiModalEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_img_url(string):\n",
    "    url = re.findall(f\"Url='(.+?)'\",string)\n",
    "    if url:return url[0]\n",
    "    return\n",
    "\n",
    "\n",
    "def get_vid_url(string):\n",
    "    url = re.findall(r\"VideoVariant\\(contentType='video/mp4', url='(.+?)',\",string)\n",
    "    if url:return url[0]\n",
    "    return\n",
    "\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "def get_image_from_url(url, timeout=5):\n",
    "    # Create a session object if it's not given\n",
    "    with requests.Session() as session:\n",
    "        try:\n",
    "            with session.get(url, stream=True, timeout=timeout) as response:\n",
    "                response.raise_for_status()  # Raises HTTPError for bad HTTP status codes\n",
    "                if 'image' in response.headers.get('Content-Type', '').lower():\n",
    "                    # Use BytesIO to load the image from the response content\n",
    "                    image = Image.open(BytesIO(response.content))\n",
    "                    \n",
    "                    # Convert the image to RGB if it's not already in RGB mode\n",
    "                    if image.mode not in ('RGB'):\n",
    "                        image = image.convert('RGB')\n",
    "                    \n",
    "                    return image\n",
    "                else:\n",
    "                    return None\n",
    "        except Exception as e:\n",
    "            return None\n",
    "\n",
    "def get_video_from_url(url):\n",
    "    try:\n",
    "        with urlopen(url) as response:\n",
    "            video_data = response.read()\n",
    "            video_bytes = BytesIO(video_data)\n",
    "            return video_bytes\n",
    "    except:\n",
    "        return\n",
    "    \n",
    "\n",
    "# df = pd.read_csv('train.csv')\n",
    "# df['img_url'] = df.media.swifter.apply(get_img_url)\n",
    "# df['vid_url'] = df.media.swifter.apply(get_vid_url)\n",
    "# analogies = df.sample(50000)\n",
    "# training = df[~df['id'].isin(analogies['id'])]\n",
    "# analogies.to_csv('dump/analogies.csv',index=False)\n",
    "# training.to_csv('dump/training.csv',index=False)\n",
    "\n",
    "analogies = pd.read_csv('dump/analogies.csv')\n",
    "training = pd.read_csv('dump/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MultiModalEncoder('cuda')\n",
    "encoder.freeze_encoders()\n",
    "_ = encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"docarray[full]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docarray import BaseDoc, DocList\n",
    "from docarray.typing import ImageUrl, VideoUrl, ID, NdArray\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Doc(BaseDoc):\n",
    "    id: ID\n",
    "    date: Optional[str] = None\n",
    "    likes: Optional[int] = None\n",
    "    content: Optional[str] = None\n",
    "    username: Optional[str] = None\n",
    "    media: Optional[str] = None\n",
    "    inferred_company: Optional[str] = None\n",
    "    img_url: Optional[ImageUrl] = None\n",
    "    vid_url: Optional[VideoUrl] = None\n",
    "    img_vector: NdArray[768]\n",
    "    vid_vector: NdArray[768]\n",
    "    text_vector: NdArray[768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list(lst, func):\n",
    "    none_positions = [i for i, x in enumerate(lst) if x is None]\n",
    "    processed_list = [x for x in lst if x is not None]\n",
    "    processed_list = func(processed_list)\n",
    "    for pos in none_positions:\n",
    "        processed_list.insert(pos, None)\n",
    "    return processed_list\n",
    "\n",
    "import torch\n",
    "@torch.inference_mode()\n",
    "def _get_embedding(to_encode,key):\n",
    "    encoded = list(encoder({key:to_encode})[key].pooler_output)\n",
    "    encoded = [x.cpu().numpy() for x in encoded]\n",
    "    return encoded\n",
    "\n",
    "def get_embedding(to_encode,key):\n",
    "    return process_list(to_encode, lambda x: _get_embedding(x,key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single threaded\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# batch_size = 16\n",
    "# docs = []\n",
    "# for i in tqdm(range(0,len(analogies),batch_size)):\n",
    "#     batch = analogies.iloc[i:i+batch_size]\n",
    "#     batch = batch.where(batch.notna(), other=None) # replace nan by None\n",
    "#     texts = batch.content.tolist()\n",
    "#     imgs = batch.img_url.apply(get_image_from_url).tolist()\n",
    "#     vids = batch.vid_url.apply(get_video_from_url).tolist()\n",
    "#     encoded_texts = get_embedding(texts,'text')\n",
    "#     encoded_imgs = get_embedding(imgs,'image')\n",
    "#     encoded_vids = get_embedding(vids,'video')\n",
    "\n",
    "#     for j in range(batch_size):\n",
    "#         docs.append(Doc(\n",
    "#             id=batch.iloc[j].id,\n",
    "#             date=batch.iloc[j].date,\n",
    "#             likes=batch.iloc[j].likes,\n",
    "#             content=batch.iloc[j].content,\n",
    "#             username=batch.iloc[j].username,\n",
    "#             inferred_company=batch.iloc[j]['inferred company'],\n",
    "#             img_url=batch.iloc[j].img_url,\n",
    "#             vid_url=batch.iloc[j].vid_url,\n",
    "#             img_vector=encoded_imgs[j],\n",
    "#             vid_vector=encoded_vids[j],\n",
    "#             text_vector=encoded_texts[j],\n",
    "#         ))\n",
    "# docs = DocList[Doc](docs)\n",
    "# docs.save_binary('dump/analogies_embeddings.pickle', compress=None, protocol='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-threaded\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Function to process a single batch\n",
    "def process_batch(batch):\n",
    "    try:\n",
    "        # Replace nan by None\n",
    "        batch = batch.where(batch.notna(), other=None)\n",
    "\n",
    "        # Load content\n",
    "        texts = batch.content.tolist()\n",
    "        imgs = batch.img_url.apply(get_image_from_url).tolist()\n",
    "        vids = batch.vid_url.apply(get_video_from_url).tolist()\n",
    "\n",
    "        # Get embeddings\n",
    "        encoded_texts = get_embedding(texts, 'text')\n",
    "        encoded_texts = [e if e is not None else np.zeros(shape=(768,)) for e in encoded_texts]\n",
    "        encoded_imgs = get_embedding(imgs, 'image')\n",
    "        encoded_imgs = [e if e is not None else np.zeros(shape=(768,)) for e in encoded_imgs]\n",
    "        encoded_vids = get_embedding(vids, 'video')\n",
    "        encoded_vids = [e if e is not None else np.zeros(shape=(768,)) for e in encoded_vids]\n",
    "\n",
    "        # Collect docs\n",
    "        batch_docs = []\n",
    "        for j in range(len(batch)):\n",
    "            batch_docs.append(\n",
    "                Doc(\n",
    "                    id=batch.iloc[j].id,\n",
    "                    date=batch.iloc[j].date,\n",
    "                    likes=batch.iloc[j].likes,\n",
    "                    content=batch.iloc[j].content,\n",
    "                    username=batch.iloc[j].username,\n",
    "                    inferred_company=batch.iloc[j]['inferred company'],\n",
    "                    img_url=batch.iloc[j].img_url,\n",
    "                    vid_url=batch.iloc[j].vid_url,\n",
    "                    img_vector=encoded_imgs[j],\n",
    "                    vid_vector=encoded_vids[j],\n",
    "                    text_vector=encoded_texts[j],\n",
    "                )\n",
    "            )\n",
    "    except:\n",
    "        return []\n",
    "    return batch_docs\n",
    "\n",
    "# Create batches\n",
    "batches = [analogies.iloc[i:i + batch_size] for i in range(0, len(analogies), batch_size)]\n",
    "\n",
    "# Use joblib to parallelize the batch processing\n",
    "n_jobs = -1  # Use all available CPU cores\n",
    "results = Parallel(n_jobs=-1,backend='threading')(delayed(process_batch)(batch) for batch in tqdm(batches))\n",
    "\n",
    "# Flatten the list of batch results to a single list of docs\n",
    "docs = [doc for batch_docs in results for doc in batch_docs]\n",
    "\n",
    "# Wrap the docs in a DocList and save\n",
    "docs = DocList[Doc](docs)\n",
    "docs.save_binary('dump/analogies_embeddings.pickle', compress=None, protocol='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
