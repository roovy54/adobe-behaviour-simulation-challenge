# -*- coding: utf-8 -*-
"""Visual_Caption

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YRXKwG7eovD3rurS_iCCtqpg0SnEZMQY
"""

import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
import pandas as pd
import sklearn
import requests
from PIL import Image

!pip install av -q
import av
import numpy as np
import torch
from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer
from transformers import AutoImageProcessor, AutoTokenizer, VisionEncoderDecoderModel
import shutil

device = "cuda" if torch.cuda.is_available() else "cpu"

# load pretrained processor, tokenizer, and model
image_processor1 = AutoImageProcessor.from_pretrained("MCG-NJU/videomae-base")
tokenizer1 = AutoTokenizer.from_pretrained("gpt2")
model1 = VisionEncoderDecoderModel.from_pretrained("Neleac/timesformer-gpt2-video-captioning").to(device)

# load pretrained processor, tokenizer, and model
model2 = VisionEncoderDecoderModel.from_pretrained("nlpconnect/vit-gpt2-image-captioning").to(device)
feature_extractor2 = ViTImageProcessor.from_pretrained("nlpconnect/vit-gpt2-image-captioning")
tokenizer2 = AutoTokenizer.from_pretrained("nlpconnect/vit-gpt2-image-captioning")

def get_content_type(url):
    try:
        response = requests.head(url)
        content_type = response.headers.get('Content-Type')
        return content_type
    except requests.ConnectionError:
        return None

def is_image_url(url):
    content_type = get_content_type(url)
    return content_type and content_type.startswith('image')

def is_video_url(url):
    content_type = get_content_type(url)
    return content_type and content_type.startswith('video')

def download_image(url, destination_path):
    try:
        # Send a GET request to the URL
        response = requests.get(url, stream=True)

        # Check if the request was successful (status code 200)
        if response.status_code == 200:
            # Open a temporary file to save the video content
            with open('temp_image.jpg', 'wb') as temp_file:
                # Copy the content from the response to the temporary file
                shutil.copyfileobj(response.raw, temp_file)

            # Move the temporary file to the destination path
            shutil.move('temp_image.jpg', destination_path)
            print(f"Image downloaded successfully to '{destination_path}'")
        else:
            print(f"Failed to download Image. Status code: {response.status_code}")
    except requests.ConnectionError:
        print("Connection error. Failed to download image.")

def download_video(url, destination_path):
    try:
        # Send a GET request to the URL
        response = requests.get(url, stream=True)

        # Check if the request was successful (status code 200)
        if response.status_code == 200:
            # Open a temporary file to save the video content
            with open('temp_video.mp4', 'wb') as temp_file:
                # Copy the content from the response to the temporary file
                shutil.copyfileobj(response.raw, temp_file)

            # Move the temporary file to the destination path
            shutil.move('temp_video.mp4', destination_path)
        else:
            print(f"Failed to download video. Status code: {response.status_code}")
    except requests.ConnectionError:
        print("Connection error. Failed to download video.")

def get_caption(url):
  video_caption = ""
  image_caption = ""
  if is_video_url(url):
    destination_path = "/content/download_video.mp4"
    download_video(url, destination_path)
    container = av.open(destination_path)

    seg_len = container.streams.video[0].frames
    clip_len = model1.config.encoder.num_frames
    indices = set(np.linspace(0, seg_len, num=clip_len, endpoint=False).astype(np.int64))
    frames = []
    container.seek(0)
    for i, frame in enumerate(container.decode(video=0)):
        if i in indices:
            frames.append(frame.to_ndarray(format="rgb24"))

    gen_kwargs = {
        "min_length": 10,
        "max_length": 20,
        "num_beams": 8,
    }

    try:
      pixel_values = image_processor1(frames, return_tensors="pt").pixel_values.to(device)
      tokens = model1.generate(pixel_values, **gen_kwargs)
      caption = tokenizer1.batch_decode(tokens, skip_special_tokens=True)[0]
      print(caption) # A man and a woman are dancing on a stage in front of a mirror.
      video_caption = caption
    except:
      pass

  if is_image_url(url):
    destination_path = '/content/download_image.jpg'
    download_image(url, destination_path)
    i_image = cv2.imread(destination_path)
    i_image = cv2.cvtColor(i_image, cv2.COLOR_BGR2RGB)

    gen_kwargs = {
        "min_length": 10,
        "max_length": 16,
        "num_beams": 4,
    }

    try:
      pixel_values = feature_extractor2(images=i_image, return_tensors="pt").pixel_values
      pixel_values = pixel_values.to(device)
      output_ids = model2.generate(pixel_values, **gen_kwargs)
      preds = tokenizer2.batch_decode(output_ids, skip_special_tokens=True)[0]
      image_caption = preds
    except:
      pass
  return video_caption, image_caption

a, b = get_caption("https://video.twimg.com/amplify_video/1019341984543268866/vid/320x180/xESU2Mmf6u4xGRH-.mp4?tag=3")
print(a,b)

